---
title: "Final Project Proposal"
author: "Gwynnie and Aria"
format: pdf
editor: source
editor_options: 
  chunk_output_type: console
---

```{r}
#| include: FALSE

library(tidyverse)
library(stringr)
library(rvest)
library(polite)
library(htmltools)
library(robotstxt)
```

1. Website(s) you plan to scrape or data sets you plan to merge
2. Variables you plan to acquire, including variables you plan to generate from your raw data
3. Questions you plan to address
4. Visualizations you envision (include photos of plot sketches!)
5. Whether you plan to build an interactive shiny app (using shiny in R, flexdashboard in Rmd, or quarto dashboard in qmd), or a scrollytelling document using closeread in qmd. 


Fires 
```{r}
# Our first table came from wikipedia, which is an allowed source
is_valid_robotstxt("https://en.wikipedia.org/wiki/Wildfires_in_the_United_States_during_2024")

#reading the html of the website
wildfires2024 <- read_html("https://en.wikipedia.org/wiki/Wildfires_in_the_United_States_during_2024")

fires2024 <- html_table(wildfires2024, header = TRUE, fill = TRUE)[[3]]
```

```{r}
county_name <- county_name |> 
  filter(county != "Land Area â–¼", county != "County / Population")
```

```{r}
get_text_from_page <- function(page, css_selector) {
  page |>
    html_nodes(css_selector) |>
    html_text()
}

scrape_countyname <- function(url) {
    Sys.sleep(2)
    page <- read_html(url)
    county_name <- get_text_from_page(page, "b span , td~ td+ td a , td+ td b")
    
    tibble(county = county_name)
}
pages <- vector("list", length = 16)
pos <- 0

for (j in 1:16) {
    pos <- pos + 1
    url <- str_c("http://www.usa.com/rank/us--land-area--county-rank.htm?hl=&hlst=&wist=&yr=&dis=&sb=DESC&plow=&phigh=&ps=", j)
    pages[[pos]] <- scrape_countyname(url)

}
county_names <- bind_rows(pages)
```

```{r}
scrape_countyarea <- function(url) {
    Sys.sleep(2)
    page <- read_html(url)
    county_area <- get_text_from_page(page, "b span , td:nth-child(2) , td b a")
    
    tibble(land_area = county_area)
}
page <- vector("list", length = 16)
pos <- 0

for (i in 1:16) {
    pos <- pos + 1
    url <- str_c("http://www.usa.com/rank/us--land-area--county-rank.htm?hl=&hlst=&wist=&yr=&dis=&sb=DESC&plow=&phigh=&ps=", i)
    page[[pos]] <- scrape_countyarea(url)

}
county_areas <- bind_rows(page)
```

